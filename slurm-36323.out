WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************


===================================BUG REPORT===================================
===================================BUG REPORT===================================

===================================BUG REPORT===================================
===================================BUG REPORT===================================Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues

Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues================================================================================
================================================================================

================================================================================
================================================================================

/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: /home/bingxing2/home/scx6503/.conda/envs/py39 did not contain libcudart.so as expected! Searching further paths...
  warn(msg)
/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: /home/bingxing2/home/scx6503/.conda/envs/py39 did not contain libcudart.so as expected! Searching further paths...
  warn(msg)
/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: /home/bingxing2/home/scx6503/.conda/envs/py39 did not contain libcudart.so as expected! Searching further paths...
  warn(msg)
/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: /home/bingxing2/home/scx6503/.conda/envs/py39 did not contain libcudart.so as expected! Searching further paths...
  warn(msg)
/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/home/bingxing2/apps/cuda/11.6.0/libnsight'), PosixPath('/home/bingxing2/apps/cuda/11.6.0/libnvvp')}
  warn(msg)
CUDA SETUP: CUDA runtime path found: /home/bingxing2/apps/cuda/11.6.0/lib64/libcudart.souda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/home/bingxing2/apps/cuda/11.6.0/libnsight'), PosixPath('/home/bingxing2/apps/cuda/11.6.0/libnvvp')}
  warn(msg)
/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/home/bingxing2/apps/cuda/11.6.0/libnvvp'), PosixPath('/home/bingxing2/apps/cuda/11.6.0/libnsight')}
  warn(msg)
/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/home/bingxing2/apps/cuda/11.6.0/libnvvp'), PosixPath('/home/bingxing2/apps/cuda/11.6.0/libnsight')}
  warn(msg)

CUDA SETUP: CUDA runtime path found: /home/bingxing2/apps/cuda/11.6.0/lib64/libcudart.soCUDA SETUP: Highest compute capability among GPUs detected: 8.0CUDA SETUP: CUDA runtime path found: /home/bingxing2/apps/cuda/11.6.0/lib64/libcudart.so
CUDA SETUP: CUDA runtime path found: /home/bingxing2/apps/cuda/11.6.0/lib64/libcudart.so

CUDA SETUP: Highest compute capability among GPUs detected: 8.0
CUDA SETUP: Detected CUDA version 116CUDA SETUP: Highest compute capability among GPUs detected: 8.0
CUDA SETUP: Highest compute capability among GPUs detected: 8.0

CUDA SETUP: Detected CUDA version 116
CUDA SETUP: Loading binary /home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda116.so...CUDA SETUP: Detected CUDA version 116
CUDA SETUP: Detected CUDA version 116

CUDA SETUP: Loading binary /home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda116.so...
CUDA SETUP: Loading binary /home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda116.so...
CUDA SETUP: Loading binary /home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda116.so...

Training Alpaca-LoRA model with params:
base_model: /home/bingxing2/home/scx6503/yx/Linly-Chinese-LLaMA-7B
data_path: /home/bingxing2/home/scx6503/yx/LaWGPT/data/Sample.json
output_dir: ./outputs/train-clm-llama-7B-2
batch_size: 32
micro_batch_size: 2
num_epochs: 800
learning_rate: 0.0003
cutoff_len: 500
val_set_size: 0
lora_r: 8
lora_alpha: 32
lora_dropout: 0.05
lora_target_modules: ['q_proj', 'v_proj', 'k_proj', 'o_proj']
train_on_inputs: True
add_eos_token: True
group_by_length: True
wandb_project: 
wandb_run_name: 
wandb_watch: 
wandb_log_model: 
resume_from_checkpoint: False
prompt template: alpaca

Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.58s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.02s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.18s/it]
pre-trained model's BOS EOS and PAD token id: 1 2 None  => It should be 1,2,none
Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.40s/it]
pre-trained model's BOS EOS and PAD token id: 1 2 None  => It should be 1,2,none
Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.88s/it]
pre-trained model's BOS EOS and PAD token id: 1 2 None  => It should be 1,2,none
Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.09s/it]
pre-trained model's BOS EOS and PAD token id: 1 2 None  => It should be 1,2,none
Found cached dataset json (/home/bingxing2/home/scx6503/.cache/huggingface/datasets/json/default-889e96a2ecc785f2/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 429.22it/s]
trainable params: 8388608 || all params: 6746804224 || trainable%: 0.12433454005023165
Map:   0%|          | 0/1057 [00:00<?, ? examples/s]Map:   4%|▎         | 39/1057 [00:00<00:02, 383.70 examples/s]Map:   8%|▊         | 80/1057 [00:00<00:02, 394.84 examples/s]Map:  11%|█▏        | 120/1057 [00:00<00:02, 393.23 examples/s]Found cached dataset json (/home/bingxing2/home/scx6503/.cache/huggingface/datasets/json/default-889e96a2ecc785f2/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 656.69it/s]
trainable params: 8388608 || all params: 6746804224 || trainable%: 0.12433454005023165
Map:   0%|          | 0/1057 [00:00<?, ? examples/s]Map:  15%|█▌        | 162/1057 [00:00<00:02, 396.57 examples/s]Map:   4%|▎         | 38/1057 [00:00<00:02, 373.36 examples/s]Map:  19%|█▉        | 202/1057 [00:00<00:02, 394.84 examples/s]Map:   7%|▋         | 78/1057 [00:00<00:02, 385.83 examples/s]Map:  23%|██▎       | 243/1057 [00:00<00:02, 393.90 examples/s]Map:  11%|█         | 118/1057 [00:00<00:02, 388.06 examples/s]Map:  27%|██▋       | 283/1057 [00:00<00:01, 394.42 examples/s]Map:  15%|█▍        | 157/1057 [00:00<00:02, 386.57 examples/s]Map:  31%|███       | 324/1057 [00:00<00:01, 395.50 examples/s]Map:  19%|█▊        | 197/1057 [00:00<00:02, 388.15 examples/s]Map:  34%|███▍      | 364/1057 [00:00<00:01, 391.48 examples/s]Map:  22%|██▏       | 236/1057 [00:00<00:02, 386.41 examples/s]Map:  38%|███▊      | 404/1057 [00:01<00:01, 393.63 examples/s]Map:  26%|██▌       | 276/1057 [00:00<00:02, 388.45 examples/s]Map:  30%|██▉       | 316/1057 [00:00<00:01, 388.47 examples/s]Map:  44%|████▍     | 464/1057 [00:01<00:01, 391.27 examples/s]Map:  34%|███▎      | 355/1057 [00:00<00:01, 384.67 examples/s]Map:  49%|████▉     | 523/1057 [00:01<00:01, 388.40 examples/s]Map:  37%|███▋      | 394/1057 [00:01<00:01, 384.45 examples/s]Map:  53%|█████▎    | 562/1057 [00:01<00:01, 385.06 examples/s]Map:  41%|████      | 433/1057 [00:01<00:01, 383.91 examples/s]Map:  57%|█████▋    | 603/1057 [00:01<00:01, 388.26 examples/s]Found cached dataset json (/home/bingxing2/home/scx6503/.cache/huggingface/datasets/json/default-889e96a2ecc785f2/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 654.95it/s]
trainable params: 8388608 || all params: 6746804224 || trainable%: 0.12433454005023165
Map:   0%|          | 0/1057 [00:00<?, ? examples/s]Map:  45%|████▍     | 473/1057 [00:01<00:01, 383.20 examples/s]Map:  61%|██████    | 643/1057 [00:01<00:01, 386.95 examples/s]Map:   4%|▎         | 39/1057 [00:00<00:02, 383.51 examples/s]Map:  50%|█████     | 531/1057 [00:01<00:01, 379.49 examples/s]Map:  65%|██████▍   | 683/1057 [00:01<00:00, 386.75 examples/s]Map:   7%|▋         | 79/1057 [00:00<00:02, 390.32 examples/s]Found cached dataset json (/home/bingxing2/home/scx6503/.cache/huggingface/datasets/json/default-889e96a2ecc785f2/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 706.11it/s]
trainable params: 8388608 || all params: 6746804224 || trainable%: 0.12433454005023165
Map:   0%|          | 0/1057 [00:00<?, ? examples/s]Map:  68%|██████▊   | 723/1057 [00:01<00:00, 386.38 examples/s]Map:  11%|█▏        | 119/1057 [00:00<00:02, 389.02 examples/s]Map:  56%|█████▌    | 588/1057 [00:01<00:01, 377.01 examples/s]Map:   4%|▎         | 38/1057 [00:00<00:02, 364.23 examples/s]Map:  72%|███████▏  | 763/1057 [00:01<00:00, 385.29 examples/s]Map:  15%|█▌        | 159/1057 [00:00<00:02, 391.85 examples/s]Map:  59%|█████▉    | 626/1057 [00:01<00:01, 375.40 examples/s]Map:   7%|▋         | 77/1057 [00:00<00:02, 375.85 examples/s]Map:  19%|█▉        | 199/1057 [00:00<00:02, 390.40 examples/s]Map:  63%|██████▎   | 664/1057 [00:01<00:01, 373.36 examples/s]Map:  77%|███████▋  | 819/1057 [00:02<00:00, 376.19 examples/s]Map:  11%|█         | 116/1057 [00:00<00:02, 378.44 examples/s]Map:  66%|██████▋   | 702/1057 [00:01<00:00, 373.94 examples/s]Map:  81%|████████  | 858/1057 [00:02<00:00, 377.95 examples/s]Map:  24%|██▍       | 258/1057 [00:00<00:02, 388.19 examples/s]Map:  15%|█▍        | 156/1057 [00:00<00:02, 381.68 examples/s]Map:  70%|███████   | 741/1057 [00:01<00:00, 375.35 examples/s]Map:  85%|████████▍ | 896/1057 [00:02<00:00, 377.97 examples/s]Map:  28%|██▊       | 297/1057 [00:00<00:01, 385.85 examples/s]Map:  18%|█▊        | 195/1057 [00:00<00:02, 382.29 examples/s]Map:  88%|████████▊ | 934/1057 [00:02<00:00, 377.03 examples/s]Map:  32%|███▏      | 336/1057 [00:00<00:01, 384.06 examples/s]Map:  75%|███████▌  | 795/1057 [00:02<00:00, 364.97 examples/s]Map:  24%|██▍       | 253/1057 [00:00<00:02, 378.87 examples/s]Map:  92%|█████████▏| 973/1057 [00:02<00:00, 377.70 examples/s]Map:  79%|███████▉  | 834/1057 [00:02<00:00, 367.71 examples/s]Map:  37%|███▋      | 394/1057 [00:01<00:01, 378.52 examples/s]Map:  28%|██▊       | 292/1057 [00:00<00:02, 379.14 examples/s]Map:  83%|████████▎ | 873/1057 [00:02<00:00, 370.83 examples/s]Map:  41%|████      | 433/1057 [00:01<00:01, 379.21 examples/s]Map:  31%|███▏      | 331/1057 [00:00<00:01, 377.55 examples/s]Map:  86%|████████▌ | 911/1057 [00:02<00:00, 369.63 examples/s]Map:  96%|█████████▋| 1020/1057 [00:02<00:00, 266.34 examples/s]Map:  45%|████▍     | 473/1057 [00:01<00:01, 381.29 examples/s]Map:  35%|███▍      | 369/1057 [00:00<00:01, 374.76 examples/s]Map:  90%|████████▉ | 949/1057 [00:02<00:00, 369.67 examples/s]Map:  39%|███▊      | 409/1057 [00:01<00:01, 376.66 examples/s]Map:  50%|█████     | 531/1057 [00:01<00:01, 379.72 examples/s]Map: 100%|██████████| 1057/1057 [00:02<00:00, 238.84 examples/s]                                                                Map:  42%|████▏     | 448/1057 [00:01<00:01, 378.29 examples/s]Map:  54%|█████▍    | 571/1057 [00:01<00:01, 380.47 examples/s]Traceback (most recent call last):
  File "/home/bingxing2/home/scx6503/yx/LaWGPT/train_clm.py", line 259, in <module>
Map:  46%|████▌     | 487/1057 [00:01<00:01, 377.61 examples/s]    fire.Fire(train)
  File "/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/fire/core.py", line 141, in Fire
    component_trace = _Fire(component, args, parsed_flag_args, context, name)
  File "/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/fire/core.py", line 466, in _Fire
    component, remaining_args = _CallAndUpdateTrace(
  File "/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/fire/core.py", line 681, in _CallAndUpdateTrace
    component = fn(*varargs, **kwargs)
  File "/home/bingxing2/home/scx6503/yx/LaWGPT/train_clm.py", line 214, in train
    args=transformers.TrainingArguments(
  File "<string>", line 111, in __init__
  File "/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/transformers/training_args.py", line 1333, in __post_init__
    and (self.device.type != "cuda")
  File "/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/transformers/training_args.py", line 1697, in device
    return self._setup_devices
  File "/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/transformers/utils/generic.py", line 54, in __get__
    cached = self.fget(obj)
  File "/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/transformers/training_args.py", line 1631, in _setup_devices
    self.distributed_state = PartialState(backend=self.ddp_backend)
  File "/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/accelerate/state.py", line 128, in __init__
Map:  95%|█████████▍| 1000/1057 [00:02<00:00, 276.01 examples/s]    torch.distributed.init_process_group(backend="nccl", **kwargs)
TypeError: torch.distributed.distributed_c10d.init_process_group() got multiple values for keyword argument 'backend'
Map:  59%|█████▉    | 628/1057 [00:01<00:01, 378.53 examples/s]Map:  50%|████▉     | 525/1057 [00:01<00:01, 376.48 examples/s]Map:  98%|█████████▊| 1040/1057 [00:02<00:00, 299.94 examples/s]Map:  63%|██████▎   | 666/1057 [00:01<00:01, 378.59 examples/s]                                                                Map:  53%|█████▎    | 565/1057 [00:01<00:01, 378.54 examples/s]Traceback (most recent call last):
  File "/home/bingxing2/home/scx6503/yx/LaWGPT/train_clm.py", line 259, in <module>
    fire.Fire(train)
  File "/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/fire/core.py", line 141, in Fire
    component_trace = _Fire(component, args, parsed_flag_args, context, name)
  File "/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/fire/core.py", line 466, in _Fire
    component, remaining_args = _CallAndUpdateTrace(
  File "/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/fire/core.py", line 681, in _CallAndUpdateTrace
    component = fn(*varargs, **kwargs)
  File "/home/bingxing2/home/scx6503/yx/LaWGPT/train_clm.py", line 214, in train
    args=transformers.TrainingArguments(
  File "<string>", line 111, in __init__
  File "/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/transformers/training_args.py", line 1333, in __post_init__
    and (self.device.type != "cuda")
  File "/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/transformers/training_args.py", line 1697, in device
    return self._setup_devices
  File "/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/transformers/utils/generic.py", line 54, in __get__
    cached = self.fget(obj)
  File "/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/transformers/training_args.py", line 1631, in _setup_devices
    self.distributed_state = PartialState(backend=self.ddp_backend)
  File "/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/accelerate/state.py", line 128, in __init__
    torch.distributed.init_process_group(backend="nccl", **kwargs)
TypeError: torch.distributed.distributed_c10d.init_process_group() got multiple values for keyword argument 'backend'
Map:  67%|██████▋   | 704/1057 [00:01<00:00, 375.94 examples/s]Map:  57%|█████▋    | 603/1057 [00:01<00:01, 375.89 examples/s]Map:  72%|███████▏  | 757/1057 [00:01<00:00, 364.13 examples/s]Map:  62%|██████▏   | 660/1057 [00:01<00:01, 374.67 examples/s]Map:  66%|██████▌   | 698/1057 [00:01<00:00, 372.68 examples/s]Map:  76%|███████▋  | 807/1057 [00:02<00:00, 351.38 examples/s]Map:  70%|██████▉   | 737/1057 [00:01<00:00, 375.13 examples/s]Map:  80%|███████▉  | 844/1057 [00:02<00:00, 353.80 examples/s]Map:  84%|████████▎ | 884/1057 [00:02<00:00, 363.02 examples/s]Map:  75%|███████▍  | 791/1057 [00:02<00:00, 367.65 examples/s]Map:  87%|████████▋ | 922/1057 [00:02<00:00, 366.91 examples/s]Map:  79%|███████▊  | 830/1057 [00:02<00:00, 370.18 examples/s]Map:  91%|█████████ | 961/1057 [00:02<00:00, 370.40 examples/s]Map:  82%|████████▏ | 868/1057 [00:02<00:00, 371.31 examples/s]Map:  95%|█████████▍| 999/1057 [00:02<00:00, 370.95 examples/s]Map:  86%|████████▌ | 907/1057 [00:02<00:00, 373.77 examples/s]Map:  91%|█████████ | 963/1057 [00:02<00:00, 370.66 examples/s]Map:  98%|█████████▊| 1041/1057 [00:02<00:00, 274.17 examples/s]                                                                Traceback (most recent call last):
  File "/home/bingxing2/home/scx6503/yx/LaWGPT/train_clm.py", line 259, in <module>
    fire.Fire(train)
  File "/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/fire/core.py", line 141, in Fire
    component_trace = _Fire(component, args, parsed_flag_args, context, name)
  File "/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/fire/core.py", line 466, in _Fire
    component, remaining_args = _CallAndUpdateTrace(
  File "/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/fire/core.py", line 681, in _CallAndUpdateTrace
    component = fn(*varargs, **kwargs)
  File "/home/bingxing2/home/scx6503/yx/LaWGPT/train_clm.py", line 214, in train
    args=transformers.TrainingArguments(
  File "<string>", line 111, in __init__
  File "/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/transformers/training_args.py", line 1333, in __post_init__
    and (self.device.type != "cuda")
  File "/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/transformers/training_args.py", line 1697, in device
    return self._setup_devices
  File "/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/transformers/utils/generic.py", line 54, in __get__
    cached = self.fget(obj)
  File "/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/transformers/training_args.py", line 1631, in _setup_devices
    self.distributed_state = PartialState(backend=self.ddp_backend)
  File "/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/accelerate/state.py", line 128, in __init__
    torch.distributed.init_process_group(backend="nccl", **kwargs)
TypeError: torch.distributed.distributed_c10d.init_process_group() got multiple values for keyword argument 'backend'
Map:  96%|█████████▋| 1020/1057 [00:02<00:00, 288.36 examples/s]Map: 100%|██████████| 1057/1057 [00:03<00:00, 248.93 examples/s]                                                                Traceback (most recent call last):
  File "/home/bingxing2/home/scx6503/yx/LaWGPT/train_clm.py", line 259, in <module>
    fire.Fire(train)
  File "/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/fire/core.py", line 141, in Fire
    component_trace = _Fire(component, args, parsed_flag_args, context, name)
  File "/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/fire/core.py", line 466, in _Fire
    component, remaining_args = _CallAndUpdateTrace(
  File "/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/fire/core.py", line 681, in _CallAndUpdateTrace
    component = fn(*varargs, **kwargs)
  File "/home/bingxing2/home/scx6503/yx/LaWGPT/train_clm.py", line 214, in train
    args=transformers.TrainingArguments(
  File "<string>", line 111, in __init__
  File "/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/transformers/training_args.py", line 1333, in __post_init__
    and (self.device.type != "cuda")
  File "/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/transformers/training_args.py", line 1697, in device
    return self._setup_devices
  File "/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/transformers/utils/generic.py", line 54, in __get__
    cached = self.fget(obj)
  File "/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/transformers/training_args.py", line 1631, in _setup_devices
    self.distributed_state = PartialState(backend=self.ddp_backend)
  File "/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/accelerate/state.py", line 128, in __init__
    torch.distributed.init_process_group(backend="nccl", **kwargs)
TypeError: torch.distributed.distributed_c10d.init_process_group() got multiple values for keyword argument 'backend'
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 1451306) of binary: /home/bingxing2/home/scx6503/.conda/envs/py39/bin/python
Traceback (most recent call last):
  File "/home/bingxing2/home/scx6503/.conda/envs/py39/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/torch/distributed/run.py", line 762, in main
    run(args)
  File "/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/bingxing2/home/scx6503/.conda/envs/py39/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train_clm.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-07-12_20:12:37
  host      : paraai-n32-h-01-agent-23.paraai-n32-h-01.com
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 1451307)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2023-07-12_20:12:37
  host      : paraai-n32-h-01-agent-23.paraai-n32-h-01.com
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 1451308)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2023-07-12_20:12:37
  host      : paraai-n32-h-01-agent-23.paraai-n32-h-01.com
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 1451309)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-07-12_20:12:37
  host      : paraai-n32-h-01-agent-23.paraai-n32-h-01.com
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 1451306)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
